{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "84853047",
      "metadata": {
        "id": "84853047"
      },
      "source": [
        "# Kingsley and Ossai\n",
        "## Project Title: Time Series Predictive Modeling Diabetes Progression and Health Risk Stratification Using Electronic Health Records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606615b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606615b4",
        "outputId": "7f1199a4-95af-4ce3-8537-801b78d8e9fc"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.preprocessing import StandardScaler    \n",
        "import pickle                                       \n",
        "import os                                           \n",
        "\n",
        "print(\"Libraries imported successfully Kingsley-Ossai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc7f5ca",
      "metadata": {
        "id": "7bc7f5ca"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01438b5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "01438b5e",
        "outputId": "374ef349-3834-4fd4-89af-eaeeef94db77"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('diabetes_dataset.csv')\n",
        "display(data.head())\n",
        "print('Columns in dataset:', list(data.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a24e2d0c",
      "metadata": {
        "id": "a24e2d0c"
      },
      "source": [
        "###  Define Features (X) and Target (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b87169c",
      "metadata": {
        "id": "4b87169c"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['Age', 'BMI', 'Blood Glucose', 'Blood Pressure', 'HbA1c', 'Insulin Level', 'Skin thickness', 'Pregnancies', 'Family history', 'Physical Activity', 'Smoking status', 'Alcohol Intake', 'Diet Type', 'Cholesterol', 'Triglycerides', 'Waiste ratio']\n",
        "target_col = 'Outcome'\n",
        "\n",
        "missing_features = [col for col in feature_cols if col not in data.columns]\n",
        "missing_target = target_col not in data.columns\n",
        "\n",
        "if missing_features:\n",
        "    print(f\"Missing feature columns in data: {missing_features}\")\n",
        "if missing_target:\n",
        "    print(f\"Missing target column in data: {target_col}\")\n",
        "\n",
        "if not missing_features and not missing_target:\n",
        "    X = data[[col for col in feature_cols if col in data.columns]]\n",
        "\n",
        "    y = data[target_col]\n",
        "\n",
        "    print(\"Features (X) and Target (y) defined.\")\n",
        "    print(f\"Shape of X: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape}\")\n",
        "else:\n",
        "    print(\"Please check your column names above and update feature_cols and target_col to match exactly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eceb9ccb",
      "metadata": {
        "id": "eceb9ccb"
      },
      "source": [
        "###  Preprocess Data: Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0eac683",
      "metadata": {
        "id": "c0eac683"
      },
      "outputs": [],
      "source": [
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "if 'X' in globals():\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    print(\"Features scaled using StandardScaler.\")\n",
        "    print(\"\\nScaler is fitted and ready to be saved.\")\n",
        "else:\n",
        "    print(\"Error: 'X' is not defined. Please run the cell that defines your features (X) and target (y) before this step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf8abdf",
      "metadata": {
        "id": "5cf8abdf"
      },
      "source": [
        "### Train the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e51bfaf",
      "metadata": {
        "id": "0e51bfaf"
      },
      "outputs": [],
      "source": [
        "# Initialize the Random Forest Classifier model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42) # random_state for reproducibility\n",
        "\n",
        "# Train the model only if X_scaled and y are defined\n",
        "if 'X_scaled' in globals() and 'y' in globals():\n",
        "    model.fit(X_scaled, y)\n",
        "    print(\"Random Forest Classifier model trained successfully!\")\n",
        "else:\n",
        "    print(\"Error: X_scaled or y is not defined. Please ensure previous cells ran successfully and column names match your data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45ad5ce",
      "metadata": {
        "id": "d45ad5ce"
      },
      "source": [
        "### Save the Model and Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fadce1c",
      "metadata": {
        "id": "2fadce1c"
      },
      "outputs": [],
      "source": [
        "# Define filenames for the saved files\n",
        "model_filename = 'diabetes_rf_model.pkl'    \n",
        "scaler_filename = 'scaler.pkl'\n",
        "\n",
        "# Save the trained model\n",
        "with open(model_filename, 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "print(f\"Model saved successfully as '{model_filename}'\")\n",
        "\n",
        "# Save the fitted scaler\n",
        "with open(scaler_filename, 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)\n",
        "print(f\"Scaler saved successfully as '{scaler_filename}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648af465",
      "metadata": {
        "id": "648af465"
      },
      "source": [
        "### Predict the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aabcce30",
      "metadata": {
        "id": "aabcce30"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    predictions = model.predict(X_scaled)\n",
        "    print(\"First 10 predictions:\", predictions[:10])\n",
        "except Exception as e:\n",
        "    print(f\"Prediction error: {e}\\nMake sure the model has been trained (fit) before calling predict. Run the training cell above and check for errors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42a7610a",
      "metadata": {
        "id": "42a7610a"
      },
      "source": [
        "### Calculate the F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9343287",
      "metadata": {
        "id": "c9343287"
      },
      "outputs": [],
      "source": [
        "# import the f1_score function\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "if 'y' in globals() and 'predictions' in globals():\n",
        "    try:\n",
        "        f1 = f1_score(y, predictions)\n",
        "        print(f'F1 Score: {f1:.2f}')\n",
        "    except ValueError as ve:\n",
        "        print(f\"ValueError: {ve}\\nCheck that y and predictions have the same length and are both defined. If you changed the number of features or retrained the model, make sure you reran all previous cells and that your scaler/model files are up to date.\")\n",
        "else:\n",
        "    print(\"Error: y or predictions is not defined. Please ensure previous cells ran successfully and the model was trained and used for prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd573bcd",
      "metadata": {},
      "source": [
        "# Save the fitted scaler using joblib (do not overwrite scaler.pkl)\n",
        "This cell saves the fitted StandardScaler to a separate file (`scaler_joblib.pkl`) to avoid interfering with the main app's scaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb0aa70",
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(scaler, 'scaler_joblib.pkl')\n",
        "print(\"Scaler saved as scaler_joblib.pkl (joblib format).\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
